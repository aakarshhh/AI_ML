{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_Update_StockLSTM",
      "provenance": [],
      "mount_file_id": "130Pst6TAyj6AovuAgFpat3_bZN9D3qBO",
      "authorship_tag": "ABX9TyNMp2LuSuxPhnWLWcjTFvEP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aakarshhh/AI_ML/blob/main/Model_Update_StockLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHEGU4egVJNR",
        "outputId": "3faf2115-ab01-409e-cc56-822f126c09c1"
      },
      "source": [
        "pip install yfinance "
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.59)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.6.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2020.12.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT_fitvkqou3"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas_datareader as dr\n",
        "import datetime as dt \n",
        "import yfinance as yf\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential \n",
        "from tensorflow.keras.layers import  Dense , Dropout ,LSTM ,BatchNormalization"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GfKzrL7qzpj",
        "outputId": "a9c05827-49a8-4bca-f549-5150c9e295b6"
      },
      "source": [
        "pred_days = 8\n",
        "d= dt.timedelta(days = 15)\n",
        "start = dt.datetime.now()- d \n",
        "end = dt.datetime.now()\n",
        "start, end"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(datetime.datetime(2021, 4, 16, 18, 50, 52, 434476),\n",
              " datetime.datetime(2021, 5, 1, 18, 50, 52, 434518))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wesnmOOWxXR_",
        "outputId": "ec27e9b4-4d53-443b-bcbf-3f5752ce1560"
      },
      "source": [
        "company=''\n",
        "for i in pd.read_excel('/content/drive/MyDrive/SentStock/tickers.xlsx',header=None)[0] :\n",
        "  company+=str(i).strip()+' '\n",
        "company  \n",
        "data = yf.download(\n",
        "        tickers = f'{company}',\n",
        "        start =start, end=end,\n",
        "        group_by = 'ticker',\n",
        "        auto_adjust = True,\n",
        "        prepost = True)\n",
        "data = pd.DataFrame(data)\n",
        "data = data[-(pred_days+1):]\n",
        "param = pd.read_csv('/content/drive/MyDrive/SentStock/param.csv',header=0).rename(index={0:'mean',1:'std',2:'pred', 3:'real'})"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  80 of 80 completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-G73i8Rfsnd"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyGJ5OhixXi5"
      },
      "source": [
        "model= Sequential()\n",
        "model.add(Dense(16, activation='relu',input_shape= ( pred_days , 1)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(LSTM( units = 16 , return_sequences=True, recurrent_dropout=0.2))\n",
        "model.add(LSTM(units = 64 ,return_sequences=True , recurrent_dropout=0.2))\n",
        "model.add(LSTM(units = 32  , recurrent_dropout=0.15))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(units = 1))\n",
        "model.compile(loss = 'mse' , optimizer = 'adam' )"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXgu5FJ4MAnP",
        "outputId": "4592882e-9c38-437e-df82-cb05bb89514c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 8, 16)             32        \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 8, 32)             544       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 8, 16)             528       \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 8, 16)             2112      \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 8, 64)             20736     \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 8)                 264       \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 36,641\n",
            "Trainable params: 36,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP_06eV8EZRY"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/SentStock/stock_lstm.keras')"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM3nmkOlSbXI"
      },
      "source": [
        "sc = StandardScaler()\n",
        "def train_model(x,y,ep = 7):\n",
        "  model.fit(x,y, epochs=ep , batch_size = 1 , verbose=2 )\n",
        "\n",
        "def save_plot(y,p,name = \"default\"):\n",
        "  plt.figure(dpi=100)\n",
        "  plt.plot(y,color=\"black\",label = \"Actual Data\")\n",
        "  plt.plot(p, color=\"green\",label = \"Predicted Data\")\n",
        "  plt.legend() \n",
        "  plt.savefig(fname = f'/content/drive/MyDrive/SentStock/Pred/{name}_'+end.strftime(\"%m_%d_%Y\")+'.jpeg')\n",
        "  plt.show()\n",
        "\n",
        "def norm(x , c ):\n",
        "  sc.mean_= param[f'{c}']['mean']\n",
        "  sc.scale_= param[f'{c}']['std']\n",
        "  return sc.transform(x)\n",
        "\n",
        "def scaled(y , c ):\n",
        "  sc.mean_= param[f'{c}']['mean']\n",
        "  sc.scale_= param[f'{c}']['std']\n",
        "  return sc.inverse_transform(y)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "hUiNwl0BFo8y",
        "outputId": "76bebc51-f3d6-41ff-d199-153dc1715e03"
      },
      "source": [
        "param"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T</th>\n",
              "      <th>TMUS</th>\n",
              "      <th>USM</th>\n",
              "      <th>VZ</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>MSFT</th>\n",
              "      <th>AMZN</th>\n",
              "      <th>GOOGL</th>\n",
              "      <th>FB</th>\n",
              "      <th>V</th>\n",
              "      <th>NVDA</th>\n",
              "      <th>MA</th>\n",
              "      <th>PYPL</th>\n",
              "      <th>NFLX</th>\n",
              "      <th>BRK-B</th>\n",
              "      <th>JPM</th>\n",
              "      <th>BAC</th>\n",
              "      <th>WFC</th>\n",
              "      <th>MS</th>\n",
              "      <th>C</th>\n",
              "      <th>BLK</th>\n",
              "      <th>AMT</th>\n",
              "      <th>PLD</th>\n",
              "      <th>CCI</th>\n",
              "      <th>EQIX</th>\n",
              "      <th>SPG</th>\n",
              "      <th>PSA</th>\n",
              "      <th>WELL</th>\n",
              "      <th>EQR</th>\n",
              "      <th>AVB</th>\n",
              "      <th>SBAC</th>\n",
              "      <th>XOM</th>\n",
              "      <th>CVX</th>\n",
              "      <th>NEP</th>\n",
              "      <th>SO</th>\n",
              "      <th>D</th>\n",
              "      <th>DUK</th>\n",
              "      <th>COP</th>\n",
              "      <th>AEP</th>\n",
              "      <th>KMI</th>\n",
              "      <th>EXC</th>\n",
              "      <th>CVS</th>\n",
              "      <th>UNH</th>\n",
              "      <th>MCK</th>\n",
              "      <th>ABC</th>\n",
              "      <th>CI</th>\n",
              "      <th>CAH</th>\n",
              "      <th>ANTM</th>\n",
              "      <th>JNJ</th>\n",
              "      <th>CNC</th>\n",
              "      <th>HUM</th>\n",
              "      <th>THO</th>\n",
              "      <th>ALGN</th>\n",
              "      <th>PPC</th>\n",
              "      <th>PATK</th>\n",
              "      <th>LCII</th>\n",
              "      <th>SHW</th>\n",
              "      <th>SAFM</th>\n",
              "      <th>LEA</th>\n",
              "      <th>CLX</th>\n",
              "      <th>LANC</th>\n",
              "      <th>DIS</th>\n",
              "      <th>CMCSA</th>\n",
              "      <th>NKE</th>\n",
              "      <th>CHTR</th>\n",
              "      <th>SNE</th>\n",
              "      <th>ATVI</th>\n",
              "      <th>MAR</th>\n",
              "      <th>LVS</th>\n",
              "      <th>VIAC</th>\n",
              "      <th>BTI</th>\n",
              "      <th>MO</th>\n",
              "      <th>DEO</th>\n",
              "      <th>EL</th>\n",
              "      <th>BUD</th>\n",
              "      <th>PM</th>\n",
              "      <th>PEP</th>\n",
              "      <th>KO</th>\n",
              "      <th>PG</th>\n",
              "      <th>GME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>24.450321</td>\n",
              "      <td>44.566161</td>\n",
              "      <td>38.059406</td>\n",
              "      <td>37.570379</td>\n",
              "      <td>32.072065</td>\n",
              "      <td>64.590405</td>\n",
              "      <td>859.369213</td>\n",
              "      <td>727.662941</td>\n",
              "      <td>124.157318</td>\n",
              "      <td>80.999486</td>\n",
              "      <td>99.722039</td>\n",
              "      <td>116.584120</td>\n",
              "      <td>83.916711</td>\n",
              "      <td>145.883873</td>\n",
              "      <td>141.482095</td>\n",
              "      <td>62.444389</td>\n",
              "      <td>17.184559</td>\n",
              "      <td>36.487451</td>\n",
              "      <td>30.929734</td>\n",
              "      <td>46.085706</td>\n",
              "      <td>303.631135</td>\n",
              "      <td>105.676356</td>\n",
              "      <td>44.389662</td>\n",
              "      <td>75.573585</td>\n",
              "      <td>283.263261</td>\n",
              "      <td>114.495597</td>\n",
              "      <td>151.183597</td>\n",
              "      <td>49.127854</td>\n",
              "      <td>48.782109</td>\n",
              "      <td>130.931329</td>\n",
              "      <td>120.746395</td>\n",
              "      <td>60.911654</td>\n",
              "      <td>83.809010</td>\n",
              "      <td>36.214221</td>\n",
              "      <td>36.889450</td>\n",
              "      <td>53.265901</td>\n",
              "      <td>59.284802</td>\n",
              "      <td>46.517598</td>\n",
              "      <td>49.959130</td>\n",
              "      <td>19.747635</td>\n",
              "      <td>30.968433</td>\n",
              "      <td>57.205391</td>\n",
              "      <td>130.421346</td>\n",
              "      <td>130.020048</td>\n",
              "      <td>65.442161</td>\n",
              "      <td>115.982080</td>\n",
              "      <td>48.802377</td>\n",
              "      <td>142.120139</td>\n",
              "      <td>90.621119</td>\n",
              "      <td>30.825420</td>\n",
              "      <td>173.509302</td>\n",
              "      <td>56.173065</td>\n",
              "      <td>119.463449</td>\n",
              "      <td>16.363864</td>\n",
              "      <td>27.223442</td>\n",
              "      <td>57.200768</td>\n",
              "      <td>89.805932</td>\n",
              "      <td>82.121464</td>\n",
              "      <td>92.642248</td>\n",
              "      <td>100.265713</td>\n",
              "      <td>94.423348</td>\n",
              "      <td>81.597940</td>\n",
              "      <td>25.472662</td>\n",
              "      <td>49.675375</td>\n",
              "      <td>221.007276</td>\n",
              "      <td>33.602675</td>\n",
              "      <td>33.912597</td>\n",
              "      <td>71.148429</td>\n",
              "      <td>43.917922</td>\n",
              "      <td>39.736406</td>\n",
              "      <td>36.238323</td>\n",
              "      <td>33.956224</td>\n",
              "      <td>103.028962</td>\n",
              "      <td>93.439237</td>\n",
              "      <td>77.917745</td>\n",
              "      <td>63.488579</td>\n",
              "      <td>83.154240</td>\n",
              "      <td>34.995058</td>\n",
              "      <td>72.478901</td>\n",
              "      <td>18.275569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.514537</td>\n",
              "      <td>28.045047</td>\n",
              "      <td>5.213497</td>\n",
              "      <td>11.366281</td>\n",
              "      <td>25.007621</td>\n",
              "      <td>52.627606</td>\n",
              "      <td>816.542032</td>\n",
              "      <td>397.142725</td>\n",
              "      <td>68.108903</td>\n",
              "      <td>57.124041</td>\n",
              "      <td>126.155829</td>\n",
              "      <td>91.676310</td>\n",
              "      <td>47.725608</td>\n",
              "      <td>146.987413</td>\n",
              "      <td>49.514474</td>\n",
              "      <td>30.069237</td>\n",
              "      <td>7.548420</td>\n",
              "      <td>11.135655</td>\n",
              "      <td>12.005330</td>\n",
              "      <td>12.739177</td>\n",
              "      <td>137.288725</td>\n",
              "      <td>61.192043</td>\n",
              "      <td>22.803271</td>\n",
              "      <td>37.074757</td>\n",
              "      <td>187.030403</td>\n",
              "      <td>35.195980</td>\n",
              "      <td>51.230161</td>\n",
              "      <td>14.343507</td>\n",
              "      <td>14.005995</td>\n",
              "      <td>37.052750</td>\n",
              "      <td>75.219011</td>\n",
              "      <td>10.374810</td>\n",
              "      <td>16.986901</td>\n",
              "      <td>11.747838</td>\n",
              "      <td>10.383461</td>\n",
              "      <td>16.064420</td>\n",
              "      <td>17.322228</td>\n",
              "      <td>10.976952</td>\n",
              "      <td>20.818898</td>\n",
              "      <td>5.423961</td>\n",
              "      <td>6.757503</td>\n",
              "      <td>19.644866</td>\n",
              "      <td>90.834072</td>\n",
              "      <td>44.225281</td>\n",
              "      <td>24.807880</td>\n",
              "      <td>59.125094</td>\n",
              "      <td>14.983675</td>\n",
              "      <td>85.072810</td>\n",
              "      <td>33.392605</td>\n",
              "      <td>21.011788</td>\n",
              "      <td>107.087471</td>\n",
              "      <td>29.470035</td>\n",
              "      <td>115.159236</td>\n",
              "      <td>8.736116</td>\n",
              "      <td>21.411300</td>\n",
              "      <td>33.388449</td>\n",
              "      <td>56.590824</td>\n",
              "      <td>36.530747</td>\n",
              "      <td>44.821734</td>\n",
              "      <td>44.993682</td>\n",
              "      <td>41.484377</td>\n",
              "      <td>35.368979</td>\n",
              "      <td>11.696775</td>\n",
              "      <td>28.176860</td>\n",
              "      <td>160.148552</td>\n",
              "      <td>18.379579</td>\n",
              "      <td>23.145703</td>\n",
              "      <td>37.693974</td>\n",
              "      <td>13.661739</td>\n",
              "      <td>14.788797</td>\n",
              "      <td>8.657033</td>\n",
              "      <td>14.054915</td>\n",
              "      <td>31.082462</td>\n",
              "      <td>54.364599</td>\n",
              "      <td>24.004296</td>\n",
              "      <td>16.178060</td>\n",
              "      <td>28.347048</td>\n",
              "      <td>8.890072</td>\n",
              "      <td>24.057638</td>\n",
              "      <td>8.613866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred</th>\n",
              "      <td>31.270288</td>\n",
              "      <td>133.072205</td>\n",
              "      <td>34.813503</td>\n",
              "      <td>56.941216</td>\n",
              "      <td>132.749603</td>\n",
              "      <td>254.896011</td>\n",
              "      <td>3438.687988</td>\n",
              "      <td>2342.884033</td>\n",
              "      <td>324.362030</td>\n",
              "      <td>232.976166</td>\n",
              "      <td>608.884460</td>\n",
              "      <td>388.098938</td>\n",
              "      <td>266.042664</td>\n",
              "      <td>503.791077</td>\n",
              "      <td>274.940948</td>\n",
              "      <td>153.032227</td>\n",
              "      <td>40.272411</td>\n",
              "      <td>45.200096</td>\n",
              "      <td>82.316475</td>\n",
              "      <td>72.315369</td>\n",
              "      <td>820.559143</td>\n",
              "      <td>252.131897</td>\n",
              "      <td>116.164032</td>\n",
              "      <td>187.224655</td>\n",
              "      <td>713.724915</td>\n",
              "      <td>121.878586</td>\n",
              "      <td>278.646179</td>\n",
              "      <td>75.654480</td>\n",
              "      <td>73.897598</td>\n",
              "      <td>192.054214</td>\n",
              "      <td>297.644806</td>\n",
              "      <td>57.302090</td>\n",
              "      <td>104.128433</td>\n",
              "      <td>74.465652</td>\n",
              "      <td>64.813225</td>\n",
              "      <td>78.748001</td>\n",
              "      <td>99.310799</td>\n",
              "      <td>51.778389</td>\n",
              "      <td>87.542610</td>\n",
              "      <td>16.935249</td>\n",
              "      <td>44.736870</td>\n",
              "      <td>76.160423</td>\n",
              "      <td>399.250671</td>\n",
              "      <td>189.723938</td>\n",
              "      <td>120.942375</td>\n",
              "      <td>249.481186</td>\n",
              "      <td>60.378250</td>\n",
              "      <td>381.841431</td>\n",
              "      <td>163.483185</td>\n",
              "      <td>61.462349</td>\n",
              "      <td>445.939178</td>\n",
              "      <td>140.183228</td>\n",
              "      <td>604.406067</td>\n",
              "      <td>24.283691</td>\n",
              "      <td>90.687927</td>\n",
              "      <td>150.144180</td>\n",
              "      <td>272.468048</td>\n",
              "      <td>162.502625</td>\n",
              "      <td>187.943115</td>\n",
              "      <td>186.619797</td>\n",
              "      <td>185.021317</td>\n",
              "      <td>184.605316</td>\n",
              "      <td>55.956684</td>\n",
              "      <td>131.921341</td>\n",
              "      <td>668.778625</td>\n",
              "      <td>104.563156</td>\n",
              "      <td>91.936409</td>\n",
              "      <td>149.704178</td>\n",
              "      <td>60.846188</td>\n",
              "      <td>40.661884</td>\n",
              "      <td>37.745823</td>\n",
              "      <td>47.029694</td>\n",
              "      <td>181.560486</td>\n",
              "      <td>315.560883</td>\n",
              "      <td>71.297668</td>\n",
              "      <td>94.854477</td>\n",
              "      <td>143.401337</td>\n",
              "      <td>54.081627</td>\n",
              "      <td>132.382599</td>\n",
              "      <td>173.338104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>real</th>\n",
              "      <td>31.410000</td>\n",
              "      <td>132.130005</td>\n",
              "      <td>34.130001</td>\n",
              "      <td>57.790001</td>\n",
              "      <td>131.460007</td>\n",
              "      <td>252.179993</td>\n",
              "      <td>3467.419922</td>\n",
              "      <td>2353.500000</td>\n",
              "      <td>325.079987</td>\n",
              "      <td>233.559998</td>\n",
              "      <td>600.380005</td>\n",
              "      <td>382.059998</td>\n",
              "      <td>262.290009</td>\n",
              "      <td>513.469971</td>\n",
              "      <td>274.950012</td>\n",
              "      <td>153.809998</td>\n",
              "      <td>40.529999</td>\n",
              "      <td>45.049999</td>\n",
              "      <td>82.550003</td>\n",
              "      <td>71.239998</td>\n",
              "      <td>819.299988</td>\n",
              "      <td>254.770004</td>\n",
              "      <td>116.529999</td>\n",
              "      <td>189.059998</td>\n",
              "      <td>720.760010</td>\n",
              "      <td>121.739998</td>\n",
              "      <td>281.160004</td>\n",
              "      <td>75.029999</td>\n",
              "      <td>74.230003</td>\n",
              "      <td>192.000000</td>\n",
              "      <td>299.720001</td>\n",
              "      <td>57.240002</td>\n",
              "      <td>103.070000</td>\n",
              "      <td>74.550003</td>\n",
              "      <td>66.169998</td>\n",
              "      <td>79.900002</td>\n",
              "      <td>100.690002</td>\n",
              "      <td>51.139999</td>\n",
              "      <td>88.709999</td>\n",
              "      <td>17.049999</td>\n",
              "      <td>44.939999</td>\n",
              "      <td>76.400002</td>\n",
              "      <td>398.799988</td>\n",
              "      <td>187.559998</td>\n",
              "      <td>120.800003</td>\n",
              "      <td>249.009995</td>\n",
              "      <td>60.340000</td>\n",
              "      <td>379.390015</td>\n",
              "      <td>162.729996</td>\n",
              "      <td>61.740002</td>\n",
              "      <td>445.239990</td>\n",
              "      <td>141.589996</td>\n",
              "      <td>595.530029</td>\n",
              "      <td>23.959999</td>\n",
              "      <td>89.599998</td>\n",
              "      <td>146.500000</td>\n",
              "      <td>273.869995</td>\n",
              "      <td>164.529999</td>\n",
              "      <td>183.839996</td>\n",
              "      <td>182.500000</td>\n",
              "      <td>184.710007</td>\n",
              "      <td>186.020004</td>\n",
              "      <td>56.150002</td>\n",
              "      <td>132.619995</td>\n",
              "      <td>673.450012</td>\n",
              "      <td>100.160004</td>\n",
              "      <td>91.190002</td>\n",
              "      <td>148.520004</td>\n",
              "      <td>61.259998</td>\n",
              "      <td>41.020000</td>\n",
              "      <td>37.509998</td>\n",
              "      <td>47.750000</td>\n",
              "      <td>179.350006</td>\n",
              "      <td>313.799988</td>\n",
              "      <td>70.959999</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>144.160004</td>\n",
              "      <td>53.980000</td>\n",
              "      <td>133.419998</td>\n",
              "      <td>173.589996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              T        TMUS        USM  ...         KO          PG         GME\n",
              "mean  24.450321   44.566161  38.059406  ...  34.995058   72.478901   18.275569\n",
              "std    5.514537   28.045047   5.213497  ...   8.890072   24.057638    8.613866\n",
              "pred  31.270288  133.072205  34.813503  ...  54.081627  132.382599  173.338104\n",
              "real  31.410000  132.130005  34.130001  ...  53.980000  133.419998  173.589996\n",
              "\n",
              "[4 rows x 80 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F57qqsT7xXaX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6523b2-ba2e-41a7-99e8-f6ada282c8a2"
      },
      "source": [
        "cou= 1 \n",
        "for c in pd.read_excel('/content/drive/MyDrive/SentStock/tickers.xlsx',header=None)[0] :\n",
        "  print(\"Training started for \"+c)\n",
        "  c = c.strip()\n",
        "  sdata =data[f'{c}']['Close'].dropna().values.reshape(-1,1) \n",
        "  \n",
        "  x_train=[]\n",
        "  y_train=[]\n",
        "  \n",
        "  param[f'{c}']['mean'] = sdata.mean()\n",
        "  param[f'{c}']['std'] = sdata.std() \n",
        "  sdata = norm(sdata ,c )\n",
        "  \n",
        "  x_train.append(sdata[:-1 ] )\n",
        "  y_train.append(sdata[-1:])\n",
        "\n",
        "  x_train,y_train = np.array(x_train) , np.array(y_train)\n",
        "  x_train= np.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))\n",
        "\n",
        "  print((x_train.shape,y_train.shape,c))\n",
        "  \n",
        "  pr = scaled(model.predict(x_train),c)\n",
        "  param[f'{c}']['pred'] = pr\n",
        "  param[f'{c}']['real'] = data[f'{c}']['Close'][-1:]\n",
        "\n",
        "  train_model(x_train,y_train)\n",
        "  print(param[f'{c}']['pred'] , param[f'{c}']['real'])\n",
        "  print(\"Training ended for \"+c)\n",
        "  print(cou)\n",
        "  cou+=1\n",
        "  print()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training started for T\n",
            "((1, 8, 1), (1, 1, 1), 'T')\n",
            "Epoch 1/7\n",
            "1/1 - 5s - loss: 0.0104\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 2.1851e-08\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 4.4601e-04\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 2.9638e-04\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0026\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0058\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 7.9719e-04\n",
            "31.448545455932617 31.40999984741211\n",
            "Training ended for T\n",
            "1\n",
            "\n",
            "Training started for TMUS\n",
            "((1, 8, 1), (1, 1, 1), 'TMUS')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 2.2807\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 2.4859\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 1.9548\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 1.9939\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 1.9690\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 1.7486\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 1.6855\n",
            "133.53359985351562 132.1300048828125\n",
            "Training ended for TMUS\n",
            "2\n",
            "\n",
            "Training started for USM\n",
            "((1, 8, 1), (1, 1, 1), 'USM')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 1.8663\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 1.8661\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 1.7824\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 1.7304\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 1.6054\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 1.6249\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 1.5832\n",
            "34.9706916809082 34.130001068115234\n",
            "Training ended for USM\n",
            "3\n",
            "\n",
            "Training started for VZ\n",
            "((1, 8, 1), (1, 1, 1), 'VZ')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.4979\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.4722\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.7302\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.5171\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.4982\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.5703\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.5204\n",
            "57.316375732421875 57.790000915527344\n",
            "Training ended for VZ\n",
            "4\n",
            "\n",
            "Training started for AAPL\n",
            "((1, 8, 1), (1, 1, 1), 'AAPL')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 2.8164\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 2.7894\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 2.7154\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 2.6115\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 2.4865\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 2.4578\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 2.4620\n",
            "133.18045043945312 131.4600067138672\n",
            "Training ended for AAPL\n",
            "5\n",
            "\n",
            "Training started for MSFT\n",
            "((1, 8, 1), (1, 1, 1), 'MSFT')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0036\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 5.3356e-05\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 8.3141e-04\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 1.5553e-04\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 4.1523e-04\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0042\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0026\n",
            "252.36001586914062 252.17999267578125\n",
            "Training ended for MSFT\n",
            "6\n",
            "\n",
            "Training started for AMZN\n",
            "((1, 8, 1), (1, 1, 1), 'AMZN')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0019\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0081\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0156\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0135\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 7.9392e-04\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0267\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 9.0412e-04\n",
            "3473.248046875 3467.419921875\n",
            "Training ended for AMZN\n",
            "7\n",
            "\n",
            "Training started for GOOGL\n",
            "((1, 8, 1), (1, 1, 1), 'GOOGL')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0345\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0387\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0366\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0181\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0168\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0036\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0136\n",
            "2362.2626953125 2353.5\n",
            "Training ended for GOOGL\n",
            "8\n",
            "\n",
            "Training started for FB\n",
            "((1, 8, 1), (1, 1, 1), 'FB')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 1.4620\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 1.2915\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 1.2812\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 1.3469\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 1.0846\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 1.1743\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 1.0562\n",
            "312.3095397949219 325.0799865722656\n",
            "Training ended for FB\n",
            "9\n",
            "\n",
            "Training started for V\n",
            "((1, 8, 1), (1, 1, 1), 'V')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.1115\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.1562\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.2067\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.2099\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.1711\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.1803\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.1193\n",
            "234.9237060546875 233.55999755859375\n",
            "Training ended for V\n",
            "10\n",
            "\n",
            "Training started for NVDA\n",
            "((1, 8, 1), (1, 1, 1), 'NVDA')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 1.0494\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.9009\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.8671\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.8723\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.8037\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.8620\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.7121\n",
            "607.4500732421875 600.3800048828125\n",
            "Training ended for NVDA\n",
            "11\n",
            "\n",
            "Training started for MA\n",
            "((1, 8, 1), (1, 1, 1), 'MA')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.4172\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.4463\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.3800\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.3361\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.3070\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.3433\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.2877\n",
            "385.6222229003906 382.05999755859375\n",
            "Training ended for MA\n",
            "12\n",
            "\n",
            "Training started for PYPL\n",
            "((1, 8, 1), (1, 1, 1), 'PYPL')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.9355\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.8686\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.8078\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.7645\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.7447\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.7416\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.7449\n",
            "265.4070739746094 262.2900085449219\n",
            "Training ended for PYPL\n",
            "13\n",
            "\n",
            "Training started for NFLX\n",
            "((1, 8, 1), (1, 1, 1), 'NFLX')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.8443\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.9217\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.9305\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.8619\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.8435\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.7454\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.7682\n",
            "501.2245178222656 513.469970703125\n",
            "Training ended for NFLX\n",
            "14\n",
            "\n",
            "Training started for BRK-B\n",
            "((1, 8, 1), (1, 1, 1), 'BRK-B')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0016\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 1.4471e-04\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0020\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0014\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 1.3575e-04\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 3.4666e-05\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 9.9410e-04\n",
            "274.8221740722656 274.95001220703125\n",
            "Training ended for BRK-B\n",
            "15\n",
            "\n",
            "Training started for JPM\n",
            "((1, 8, 1), (1, 1, 1), 'JPM')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0785\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0925\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.1063\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0683\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0747\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0541\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0504\n",
            "153.1249237060547 153.80999755859375\n",
            "Training ended for JPM\n",
            "16\n",
            "\n",
            "Training started for BAC\n",
            "((1, 8, 1), (1, 1, 1), 'BAC')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0320\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0215\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0234\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0124\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0073\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0016\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 3.1793e-04\n",
            "40.372047424316406 40.529998779296875\n",
            "Training ended for BAC\n",
            "17\n",
            "\n",
            "Training started for WFC\n",
            "((1, 8, 1), (1, 1, 1), 'WFC')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.2459\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.3347\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.2377\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.1994\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.2662\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.2329\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.1363\n",
            "45.668331146240234 45.04999923706055\n",
            "Training ended for WFC\n",
            "18\n",
            "\n",
            "Training started for MS\n",
            "((1, 8, 1), (1, 1, 1), 'MS')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0096\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0231\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0410\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0221\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0376\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0764\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0491\n",
            "82.26673889160156 82.55000305175781\n",
            "Training ended for MS\n",
            "19\n",
            "\n",
            "Training started for C\n",
            "((1, 8, 1), (1, 1, 1), 'C')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.4358\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.4529\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.4458\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.3270\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.2411\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.3806\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.1544\n",
            "72.1843032836914 71.23999786376953\n",
            "Training ended for C\n",
            "20\n",
            "\n",
            "Training started for BLK\n",
            "((1, 8, 1), (1, 1, 1), 'BLK')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.1561\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.3377\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.2062\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.2223\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.3215\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.1531\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.1014\n",
            "815.75146484375 819.2999877929688\n",
            "Training ended for BLK\n",
            "21\n",
            "\n",
            "Training started for AMT\n",
            "((1, 8, 1), (1, 1, 1), 'AMT')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 14.0297\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 13.8341\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 12.9250\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 12.5145\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 12.0306\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 11.6043\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 11.1407\n",
            "250.196533203125 254.77000427246094\n",
            "Training ended for AMT\n",
            "22\n",
            "\n",
            "Training started for PLD\n",
            "((1, 8, 1), (1, 1, 1), 'PLD')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 2.0132\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 2.2202\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 1.9883\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 1.9483\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 1.7278\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 1.6955\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 1.6575\n",
            "115.57320404052734 116.52999877929688\n",
            "Training ended for PLD\n",
            "23\n",
            "\n",
            "Training started for CCI\n",
            "((1, 8, 1), (1, 1, 1), 'CCI')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 1.3519\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 1.3169\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 1.2692\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 1.0167\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.9885\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.8617\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.7969\n",
            "186.66676330566406 189.05999755859375\n",
            "Training ended for CCI\n",
            "24\n",
            "\n",
            "Training started for EQIX\n",
            "((1, 8, 1), (1, 1, 1), 'EQIX')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 2.0504\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 1.9975\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 2.0007\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 1.9662\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 1.7619\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 1.6664\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 1.5876\n",
            "710.942626953125 720.760009765625\n",
            "Training ended for EQIX\n",
            "25\n",
            "\n",
            "Training started for SPG\n",
            "((1, 8, 1), (1, 1, 1), 'SPG')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0239\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0369\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0426\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0044\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0050\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0292\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0068\n",
            "121.02079010009766 121.73999786376953\n",
            "Training ended for SPG\n",
            "26\n",
            "\n",
            "Training started for PSA\n",
            "((1, 8, 1), (1, 1, 1), 'PSA')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.9423\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.9512\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.8527\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.7980\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.5855\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.7156\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.5318\n",
            "278.682861328125 281.1600036621094\n",
            "Training ended for PSA\n",
            "27\n",
            "\n",
            "Training started for WELL\n",
            "((1, 8, 1), (1, 1, 1), 'WELL')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 2.9428\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 2.7043\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 2.6663\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 2.4477\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 2.3655\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 2.3895\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 2.0502\n",
            "75.76483917236328 75.02999877929688\n",
            "Training ended for WELL\n",
            "28\n",
            "\n",
            "Training started for EQR\n",
            "((1, 8, 1), (1, 1, 1), 'EQR')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.2563\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.2430\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.2392\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.2440\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.2225\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.2253\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.2341\n",
            "74.02588653564453 74.2300033569336\n",
            "Training ended for EQR\n",
            "29\n",
            "\n",
            "Training started for AVB\n",
            "((1, 8, 1), (1, 1, 1), 'AVB')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0384\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0378\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0533\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0213\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0202\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0296\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0477\n",
            "192.23385620117188 192.0\n",
            "Training ended for AVB\n",
            "30\n",
            "\n",
            "Training started for SBAC\n",
            "((1, 8, 1), (1, 1, 1), 'SBAC')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 1.1037e-04\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0022\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0227\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0245\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0118\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0045\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0028\n",
            "299.4902038574219 299.7200012207031\n",
            "Training ended for SBAC\n",
            "31\n",
            "\n",
            "Training started for XOM\n",
            "((1, 8, 1), (1, 1, 1), 'XOM')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 5.1453\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 4.6250\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 4.6437\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 3.9893\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 3.4089\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 2.7567\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 2.3494\n",
            "60.030738830566406 57.2400016784668\n",
            "Training ended for XOM\n",
            "32\n",
            "\n",
            "Training started for CVX\n",
            "((1, 8, 1), (1, 1, 1), 'CVX')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 4.4964\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 3.7859\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 3.1173\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 3.1740\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 2.6605\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 2.5483\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 1.7436\n",
            "107.07978057861328 103.06999969482422\n",
            "Training ended for CVX\n",
            "33\n",
            "\n",
            "Training started for NEP\n",
            "((1, 8, 1), (1, 1, 1), 'NEP')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.1686\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0793\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0530\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0640\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0539\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0424\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0521\n",
            "74.97241973876953 74.55000305175781\n",
            "Training ended for NEP\n",
            "34\n",
            "\n",
            "Training started for SO\n",
            "((1, 8, 1), (1, 1, 1), 'SO')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 1.0916\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 1.2939\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 1.0429\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.8998\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.9945\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.8121\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.8629\n",
            "65.48578643798828 66.16999816894531\n",
            "Training ended for SO\n",
            "35\n",
            "\n",
            "Training started for D\n",
            "((1, 8, 1), (1, 1, 1), 'D')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0865\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0160\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0184\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 1.9055e-04\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0066\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 1.0566e-04\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0013\n",
            "79.74627685546875 79.9000015258789\n",
            "Training ended for D\n",
            "36\n",
            "\n",
            "Training started for DUK\n",
            "((1, 8, 1), (1, 1, 1), 'DUK')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.1087\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0479\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0685\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0110\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0113\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0026\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0064\n",
            "100.47529602050781 100.69000244140625\n",
            "Training ended for DUK\n",
            "37\n",
            "\n",
            "Training started for COP\n",
            "((1, 8, 1), (1, 1, 1), 'COP')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0010\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0197\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0295\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0266\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0146\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0012\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0024\n",
            "50.938690185546875 51.13999938964844\n",
            "Training ended for COP\n",
            "38\n",
            "\n",
            "Training started for AEP\n",
            "((1, 8, 1), (1, 1, 1), 'AEP')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.3482\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.2469\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.3128\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.2469\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.3280\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.2545\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0744\n",
            "89.29320526123047 88.70999908447266\n",
            "Training ended for AEP\n",
            "39\n",
            "\n",
            "Training started for KMI\n",
            "((1, 8, 1), (1, 1, 1), 'KMI')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.5976\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.5235\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.3218\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.4701\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.4719\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.3600\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.1544\n",
            "16.780000686645508 17.049999237060547\n",
            "Training ended for KMI\n",
            "40\n",
            "\n",
            "Training started for EXC\n",
            "((1, 8, 1), (1, 1, 1), 'EXC')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.3601\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.3192\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.5335\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.1209\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.5701\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.2458\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.5552\n",
            "45.22821807861328 44.939998626708984\n",
            "Training ended for EXC\n",
            "41\n",
            "\n",
            "Training started for CVS\n",
            "((1, 8, 1), (1, 1, 1), 'CVS')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0060\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0080\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0041\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0165\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 1.5526e-04\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 1.3659e-04\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0144\n",
            "76.44242858886719 76.4000015258789\n",
            "Training ended for CVS\n",
            "42\n",
            "\n",
            "Training started for UNH\n",
            "((1, 8, 1), (1, 1, 1), 'UNH')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.6396\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.5581\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.6260\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.5138\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.4184\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.5054\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.4540\n",
            "400.66357421875 398.79998779296875\n",
            "Training ended for UNH\n",
            "43\n",
            "\n",
            "Training started for MCK\n",
            "((1, 8, 1), (1, 1, 1), 'MCK')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 2.3668\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 2.0397\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 2.1390\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 2.0591\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 1.8895\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 1.8595\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 1.5881\n",
            "192.4526824951172 187.55999755859375\n",
            "Training ended for MCK\n",
            "44\n",
            "\n",
            "Training started for ABC\n",
            "((1, 8, 1), (1, 1, 1), 'ABC')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.1495\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0621\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0023\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0185\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0510\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0284\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0609\n",
            "121.0894775390625 120.80000305175781\n",
            "Training ended for ABC\n",
            "45\n",
            "\n",
            "Training started for CI\n",
            "((1, 8, 1), (1, 1, 1), 'CI')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.7799\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.8192\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.8213\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.7359\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.6381\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.5512\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.6300\n",
            "250.78115844726562 249.00999450683594\n",
            "Training ended for CI\n",
            "46\n",
            "\n",
            "Training started for CAH\n",
            "((1, 8, 1), (1, 1, 1), 'CAH')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.2740\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.2280\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.2141\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.2464\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.1507\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.1720\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.1704\n",
            "60.64179611206055 60.34000015258789\n",
            "Training ended for CAH\n",
            "47\n",
            "\n",
            "Training started for ANTM\n",
            "((1, 8, 1), (1, 1, 1), 'ANTM')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.1156\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.1895\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0986\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.1095\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0724\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0769\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0474\n",
            "380.5855712890625 379.3900146484375\n",
            "Training ended for ANTM\n",
            "48\n",
            "\n",
            "Training started for JNJ\n",
            "((1, 8, 1), (1, 1, 1), 'JNJ')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.5847\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.5978\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.5666\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.4842\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.5170\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.4784\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.4864\n",
            "163.93487548828125 162.72999572753906\n",
            "Training ended for JNJ\n",
            "49\n",
            "\n",
            "Training started for CNC\n",
            "((1, 8, 1), (1, 1, 1), 'CNC')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0201\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0114\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0118\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0178\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0198\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0135\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0094\n",
            "62.071144104003906 61.7400016784668\n",
            "Training ended for CNC\n",
            "50\n",
            "\n",
            "Training started for HUM\n",
            "((1, 8, 1), (1, 1, 1), 'HUM')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.2223\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.2801\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.2449\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.2542\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.2763\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.2897\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.2448\n",
            "443.7146911621094 445.239990234375\n",
            "Training ended for HUM\n",
            "51\n",
            "\n",
            "Training started for THO\n",
            "((1, 8, 1), (1, 1, 1), 'THO')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.6634\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.6387\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.6745\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.6263\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.6084\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.5888\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.4983\n",
            "138.78883361816406 141.58999633789062\n",
            "Training ended for THO\n",
            "52\n",
            "\n",
            "Training started for ALGN\n",
            "((1, 8, 1), (1, 1, 1), 'ALGN')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 1.2746\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 1.3200\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 1.3036\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 1.2868\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 1.3177\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 1.2397\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 1.2763\n",
            "606.1064453125 595.530029296875\n",
            "Training ended for ALGN\n",
            "53\n",
            "\n",
            "Training started for PPC\n",
            "((1, 8, 1), (1, 1, 1), 'PPC')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 2.0968\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 2.0661\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 2.0244\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 1.9784\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 1.9146\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 1.9210\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 1.8440\n",
            "24.320829391479492 23.959999084472656\n",
            "Training ended for PPC\n",
            "54\n",
            "\n",
            "Training started for PATK\n",
            "((1, 8, 1), (1, 1, 1), 'PATK')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0107\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0135\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0100\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0066\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0067\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0038\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0023\n",
            "90.02909088134766 89.5999984741211\n",
            "Training ended for PATK\n",
            "55\n",
            "\n",
            "Training started for LCII\n",
            "((1, 8, 1), (1, 1, 1), 'LCII')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0821\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0966\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0677\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0644\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.1014\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0880\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0765\n",
            "145.2438507080078 146.5\n",
            "Training ended for LCII\n",
            "56\n",
            "\n",
            "Training started for SHW\n",
            "((1, 8, 1), (1, 1, 1), 'SHW')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 2.7645\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 2.4941\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 2.4619\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 2.4967\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 1.8412\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 1.8505\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 1.9679\n",
            "270.13653564453125 273.8699951171875\n",
            "Training ended for SHW\n",
            "57\n",
            "\n",
            "Training started for SAFM\n",
            "((1, 8, 1), (1, 1, 1), 'SAFM')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.4247\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.3845\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.3811\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.2158\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.2641\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.2327\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.2028\n",
            "162.84912109375 164.52999877929688\n",
            "Training ended for SAFM\n",
            "58\n",
            "\n",
            "Training started for LEA\n",
            "((1, 8, 1), (1, 1, 1), 'LEA')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0126\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0169\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0111\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0108\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0104\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0093\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0087\n",
            "182.97576904296875 183.83999633789062\n",
            "Training ended for LEA\n",
            "59\n",
            "\n",
            "Training started for CLX\n",
            "((1, 8, 1), (1, 1, 1), 'CLX')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.8929\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.8286\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.8430\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.8778\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.8452\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.8109\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.9085\n",
            "186.72201538085938 182.5\n",
            "Training ended for CLX\n",
            "60\n",
            "\n",
            "Training started for LANC\n",
            "((1, 8, 1), (1, 1, 1), 'LANC')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.1217\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0717\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0436\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0986\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0836\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0347\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0655\n",
            "185.04452514648438 184.7100067138672\n",
            "Training ended for LANC\n",
            "61\n",
            "\n",
            "Training started for DIS\n",
            "((1, 8, 1), (1, 1, 1), 'DIS')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 1.7584\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 1.8040\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 1.8156\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 1.5511\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 1.6909\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 1.7457\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 1.6669\n",
            "184.50857543945312 186.02000427246094\n",
            "Training ended for DIS\n",
            "62\n",
            "\n",
            "Training started for CMCSA\n",
            "((1, 8, 1), (1, 1, 1), 'CMCSA')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.6253\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.7330\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.6723\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.6037\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.6073\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.5254\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.4900\n",
            "55.46028137207031 56.150001525878906\n",
            "Training ended for CMCSA\n",
            "63\n",
            "\n",
            "Training started for NKE\n",
            "((1, 8, 1), (1, 1, 1), 'NKE')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0477\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0185\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0287\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0097\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0115\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0092\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0149\n",
            "132.29840087890625 132.6199951171875\n",
            "Training ended for NKE\n",
            "64\n",
            "\n",
            "Training started for CHTR\n",
            "((1, 8, 1), (1, 1, 1), 'CHTR')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.9504\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.9730\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.9368\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.9583\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.8265\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.8318\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.7483\n",
            "666.04248046875 673.4500122070312\n",
            "Training ended for CHTR\n",
            "65\n",
            "\n",
            "Training started for SNE\n",
            "((1, 8, 1), (1, 1, 1), 'SNE')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 3.0871\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 3.0830\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 3.1338\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 2.9668\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 3.0652\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 2.9979\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 2.9895\n",
            "105.39241790771484 100.16000366210938\n",
            "Training ended for SNE\n",
            "66\n",
            "\n",
            "Training started for ATVI\n",
            "((1, 8, 1), (1, 1, 1), 'ATVI')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.6738\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.7867\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.6612\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.6873\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.6319\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.5944\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.5480\n",
            "92.24421691894531 91.19000244140625\n",
            "Training ended for ATVI\n",
            "67\n",
            "\n",
            "Training started for MAR\n",
            "((1, 8, 1), (1, 1, 1), 'MAR')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.6083\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.6081\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.5999\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.5254\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.5971\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.5324\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.5776\n",
            "150.5312042236328 148.52000427246094\n",
            "Training ended for MAR\n",
            "68\n",
            "\n",
            "Training started for LVS\n",
            "((1, 8, 1), (1, 1, 1), 'LVS')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 1.4841\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 1.6547\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 1.6659\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 1.6525\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 1.3752\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 1.4602\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 1.4175\n",
            "59.81895446777344 61.2599983215332\n",
            "Training ended for LVS\n",
            "69\n",
            "\n",
            "Training started for VIAC\n",
            "((1, 8, 1), (1, 1, 1), 'VIAC')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.3893\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.3634\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.4556\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.3515\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.3164\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.3133\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.2764\n",
            "40.200843811035156 41.02000045776367\n",
            "Training ended for VIAC\n",
            "70\n",
            "\n",
            "Training started for BTI\n",
            "((1, 8, 1), (1, 1, 1), 'BTI')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0139\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0128\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0141\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0136\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0201\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0254\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0197\n",
            "37.55510330200195 37.5099983215332\n",
            "Training ended for BTI\n",
            "71\n",
            "\n",
            "Training started for MO\n",
            "((1, 8, 1), (1, 1, 1), 'MO')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 6.2587\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 6.0468\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 6.0581\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 5.8894\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 5.7627\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 5.5848\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 5.3914\n",
            "46.79800033569336 47.75\n",
            "Training ended for MO\n",
            "72\n",
            "\n",
            "Training started for DEO\n",
            "((1, 8, 1), (1, 1, 1), 'DEO')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 3.8563\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 3.8462\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 3.7542\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 3.6506\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 3.3614\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 3.4158\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 3.2588\n",
            "182.2099609375 179.35000610351562\n",
            "Training ended for DEO\n",
            "73\n",
            "\n",
            "Training started for EL\n",
            "((1, 8, 1), (1, 1, 1), 'EL')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.5168\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.5279\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.4708\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.4499\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.4617\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.4839\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.4546\n",
            "315.6506042480469 313.79998779296875\n",
            "Training ended for EL\n",
            "74\n",
            "\n",
            "Training started for BUD\n",
            "((1, 8, 1), (1, 1, 1), 'BUD')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0349\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0393\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0345\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0260\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0249\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0145\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0240\n",
            "71.21971893310547 70.95999908447266\n",
            "Training ended for BUD\n",
            "75\n",
            "\n",
            "Training started for PM\n",
            "((1, 8, 1), (1, 1, 1), 'PM')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.4304\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.4541\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.4404\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.4942\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.4956\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.4295\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.4909\n",
            "94.742919921875 95.0\n",
            "Training ended for PM\n",
            "76\n",
            "\n",
            "Training started for PEP\n",
            "((1, 8, 1), (1, 1, 1), 'PEP')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0074\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0037\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0017\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 7.3789e-06\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 7.8193e-04\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.0023\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0086\n",
            "144.21328735351562 144.16000366210938\n",
            "Training ended for PEP\n",
            "77\n",
            "\n",
            "Training started for KO\n",
            "((1, 8, 1), (1, 1, 1), 'KO')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.7759\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.5852\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.5317\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.6712\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.3848\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.5913\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.3741\n",
            "54.283111572265625 53.97999954223633\n",
            "Training ended for KO\n",
            "78\n",
            "\n",
            "Training started for PG\n",
            "((1, 8, 1), (1, 1, 1), 'PG')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.0938\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.1192\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0880\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.1018\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.1233\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.1127\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.1021\n",
            "132.78433227539062 133.4199981689453\n",
            "Training ended for PG\n",
            "79\n",
            "\n",
            "Training started for GME\n",
            "((1, 8, 1), (1, 1, 1), 'GME')\n",
            "Epoch 1/7\n",
            "1/1 - 0s - loss: 0.1148\n",
            "Epoch 2/7\n",
            "1/1 - 0s - loss: 0.0757\n",
            "Epoch 3/7\n",
            "1/1 - 0s - loss: 0.0942\n",
            "Epoch 4/7\n",
            "1/1 - 0s - loss: 0.0818\n",
            "Epoch 5/7\n",
            "1/1 - 0s - loss: 0.0799\n",
            "Epoch 6/7\n",
            "1/1 - 0s - loss: 0.1101\n",
            "Epoch 7/7\n",
            "1/1 - 0s - loss: 0.0863\n",
            "170.4827117919922 173.58999633789062\n",
            "Training ended for GME\n",
            "80\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm-SGbMiPIcn"
      },
      "source": [
        "param = param.dropna(axis=1,)\n",
        "a = param.loc[['real','pred']]\n",
        "a.to_excel('/content/drive/MyDrive/SentStock/preds.xlsx')\n",
        "param.to_csv('/content/drive/MyDrive/SentStock/param.csv',index=False)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynswzP4z4Rp6"
      },
      "source": [
        "model.save('/content/drive/MyDrive/SentStock/stock_lstm.keras')"
      ],
      "execution_count": 154,
      "outputs": []
    }
  ]
}